{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | ResNet           | 25.8 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "17.3 M    Trainable params\n",
      "8.5 M     Non-trainable params\n",
      "25.8 M    Total params\n",
      "103.265   Total estimated model params size (MB)\n",
      "155       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ccbbd9a17c40ab9021b32996ff1df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomNetwork(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=205, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import typing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import albumentations as A\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import scipy\n",
    "import skimage\n",
    "import skimage.filters\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# !Этих импортов достаточно для решения данного задания\n",
    "\n",
    "CLASSES_CNT = 205\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class DatasetRTSD(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Класс для чтения и хранения датасета.\n",
    "\n",
    "    :param root_folders: список путей до папок с данными\n",
    "    :param path_to_classes_json: путь до classes.json\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_folders: typing.List[str],\n",
    "        path_to_classes_json: str,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.classes, self.class_to_idx = self.get_classes(path_to_classes_json)\n",
    "        self.samples = []\n",
    "        for root_folder in root_folders:\n",
    "            for folder in os.listdir(root_folder):\n",
    "                path = os.path.join(root_folder, folder)\n",
    "                for filename in os.listdir(path):\n",
    "                    self.samples.append((os.path.join(path, filename), self.class_to_idx[folder]))\n",
    "        self.classes_to_samples = {i: [] for i in range(len(self.classes))}\n",
    "        for i, (img_path, class_idx) in enumerate(self.samples):\n",
    "            self.classes_to_samples[class_idx].append(i)\n",
    "\n",
    "        self.augmentations = A.Compose([\n",
    "            A.Rotate(limit=30),\n",
    "        ])\n",
    "\n",
    "        self.transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(size=(64, 64)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index: int) -> typing.Tuple[torch.Tensor, str, int]:\n",
    "        \"\"\"\n",
    "        Возвращает тройку: тензор с картинкой, путь до файла, номер класса файла (если нет разметки, то \"-1\").\n",
    "        \"\"\"\n",
    "        img_path, class_idx = self.samples[index]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        aug_img_pts = self.augmentations(image=np.array(image, dtype=np.uint8))\n",
    "        aug_image = aug_img_pts[\"image\"]\n",
    "        image = Image.fromarray(aug_image.astype(np.uint8))\n",
    "        image = self.transform(image)\n",
    "        return image, img_path, class_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def get_classes(\n",
    "        path_to_classes_json,\n",
    "    ) -> typing.Tuple[typing.List[str], typing.Mapping[str, int]]:\n",
    "        \"\"\"\n",
    "        Считывает из classes.json информацию о классах.\n",
    "\n",
    "        :param path_to_classes_json: путь до classes.json\n",
    "        \"\"\"\n",
    "        with open(path_to_classes_json, 'r') as f:\n",
    "            class_to_idx = {name: info[\"id\"] for name, info in json.load(f).items()}\n",
    "        return list(class_to_idx.keys()), class_to_idx\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Возвращает размер датасета (количество сэмплов).\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "class TestData(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Класс для чтения и хранения тестового датасета.\n",
    "\n",
    "    :param root: путь до папки с картинками знаков\n",
    "    :param path_to_classes_json: путь до classes.json\n",
    "    :param annotations_file: путь до .csv-файла с аннотациями (опциональный)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        path_to_classes_json: str,\n",
    "        annotations_file: str = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.samples = []\n",
    "        for image in os.listdir(root):\n",
    "            self.samples.append(image)\n",
    "        self.transform =  A.Compose([\n",
    "            A.Resize(224, 224),\n",
    "            A.ToFloat(max_value=255),\n",
    "            A.Normalize(max_pixel_value=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            A.pytorch.transforms.ToTensorV2(),\n",
    "        ])\n",
    "        self.targets = None\n",
    "        if annotations_file is not None:\n",
    "            self.classes, self.class_to_idx = self.get_classes(path_to_classes_json)\n",
    "            self.targets = {}\n",
    "            with open(annotations_file, 'r') as f:\n",
    "                next(f)\n",
    "                for line in f:\n",
    "                    img_path, class_name = line.strip().split(',')\n",
    "                    self.targets[img_path] = self.class_to_idx[class_name]\n",
    "\n",
    "    def __getitem__(self, index: int) -> typing.Tuple[torch.Tensor, str, int]:\n",
    "        \"\"\"\n",
    "        Возвращает тройку: тензор с картинкой, путь до файла, номер класса файла (если нет разметки, то \"-1\").\n",
    "        \"\"\"\n",
    "        img_path = self.samples[index]\n",
    "        image = Image.open(os.path.join(self.root, img_path)).convert('RGB')\n",
    "        image = self.transform(image=np.array(image))\n",
    "        class_idx = self.targets.get(img_path, -1) if self.targets else -1\n",
    "        return image, img_path, class_idx\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_classes(\n",
    "        path_to_classes_json,\n",
    "    ) -> typing.Tuple[typing.List[str], typing.Mapping[str, int]]:\n",
    "        \"\"\"\n",
    "        Считывает из classes.json информацию о классах.\n",
    "\n",
    "        :param path_to_classes_json: путь до classes.json\n",
    "        \"\"\"\n",
    "        with open(path_to_classes_json, 'r') as f:\n",
    "            class_to_idx = {name: info[\"id\"] for name, info in json.load(f).items()}\n",
    "        return list(class_to_idx.keys()), class_to_idx\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Возвращает размер датасета (количество сэмплов).\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "class CustomNetwork(L.LightningModule):\n",
    "    \"\"\"\n",
    "    Класс, реализующий нейросеть для классификации.\n",
    "\n",
    "    :param features_criterion: loss-функция на признаки, извлекаемые нейросетью перед классификацией (None когда нет такого лосса)\n",
    "    :param internal_features: внутреннее число признаков\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        features_criterion: (\n",
    "            typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor] | None\n",
    "        ) = None,\n",
    "        internal_features: int = 1024,\n",
    "        transfer = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        weights = torchvision.models.ResNet50_Weights.DEFAULT if transfer else None\n",
    "        model = torchvision.models.resnet50(weights=weights)\n",
    "        # model = torchvision.models.resnet50(pretrained=transfer)\n",
    "        old_in_features = model.fc.in_features\n",
    "        model.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(old_in_features, internal_features),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(internal_features, CLASSES_CNT)\n",
    "        )\n",
    "        for child in list(model.children())[:-3]:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.model = model.to(DEVICE)\n",
    "        self.features_criterion = features_criterion\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Функция для прогона данных через нейронную сеть.\n",
    "        Возвращает два тензора: внутреннее представление и логиты после слоя-классификатора.\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "    def predict(self, x: torch.Tensor) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Функция для предсказания классов-ответов. Возвращает np-массив с индексами классов.\n",
    "\n",
    "        :param x: батч с картинками\n",
    "        \"\"\"\n",
    "        return self.forward(x).argmax(dim=1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=5e-4)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=5,\n",
    "            gamma=0.1,\n",
    "        )\n",
    "        lr_scheduler_config = {\n",
    "            \"scheduler\": lr_scheduler,\n",
    "            \"interval\": \"epoch\",\n",
    "            \"frequency\": 1,\n",
    "        }\n",
    "        return [optimizer], [lr_scheduler_config]\n",
    "\n",
    "    # def cross_entropy_loss(self, logits, labels):\n",
    "    #     return torch.nn.functional.nll_loss(logits, labels)\n",
    "\n",
    "    # def training_step(self, train_batch, batch_idx):\n",
    "    #     x, _, y = train_batch\n",
    "    #     additional_loss = 0\n",
    "    #     if self.features_criterion is not None:\n",
    "    #         out = []\n",
    "    #         for xx in x:\n",
    "    #             out.append(self.feature_net(xx.unsqueeze(0)))\n",
    "\n",
    "    #         loss = self.features_criterion(out, y)\n",
    "    #         logs = {'train_loss': loss}\n",
    "    #         self.log('train_loss', loss, on_step=True, prog_bar=True)\n",
    "    #         return {'loss': loss, 'log': logs}\n",
    "\n",
    "    #     logits = self.forward(x)\n",
    "    #     loss = self.cross_entropy_loss(logits, y) \n",
    "    #     logs = {'train_loss': loss}\n",
    "\n",
    "    #     acc = torch.sum(logits.argmax(dim=1) == y) / y.shape[0]\n",
    "    #     self.log('train_acc', acc, on_step=True, prog_bar=True)\n",
    "    #     self.log('train_loss', loss, on_step=True, prog_bar=True)\n",
    "    #     return {'loss': loss, 'log': logs}\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x, _, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        accs = (logits.argmax(dim=1) == y).sum() / y.shape[0]\n",
    "        metrics = {}\n",
    "        if loss is not None:\n",
    "            metrics[f\"train_loss\"] = loss\n",
    "        if accs is not None:\n",
    "            metrics[f\"train_accs\"] = accs\n",
    "        self.log_dict(\n",
    "            metrics,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "            on_step=\"train\" == \"train\",\n",
    "            on_epoch=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_simple_classifier() -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Функция для обучения простого классификатора на исходных данных.\n",
    "    \"\"\"\n",
    "    ds_train = DatasetRTSD(\n",
    "        root_folders=['./cropped-train'],\n",
    "        path_to_classes_json='./classes.json'\n",
    "    )\n",
    "    dl_train = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=os.cpu_count(),\n",
    "    )\n",
    "    model = CustomNetwork(transfer=True)\n",
    "    trainer = L.Trainer(max_epochs=1)\n",
    "    trainer.fit(model, dl_train)\n",
    "    torch.save(model.state_dict(), \"simple_model.pth\")\n",
    "    return model\n",
    "\n",
    "train_simple_classifier()\n",
    "# def apply_classifier(\n",
    "#     model: torch.nn.Module,\n",
    "#     test_folder: str,\n",
    "#     path_to_classes_json: str,\n",
    "# ) -> typing.List[typing.Mapping[str, typing.Any]]:\n",
    "#     \"\"\"\n",
    "#     Функция, которая применяет модель и получает её предсказания.\n",
    "\n",
    "#     :param model: модель, которую нужно протестировать\n",
    "#     :param test_folder: путь до папки с тестовыми данными\n",
    "#     :param path_to_classes_json: путь до файла с информацией о классах classes.json\n",
    "#     \"\"\"\n",
    "#     ### YOUR CODE HERE - список словарей вида {'filename': 'имя файла', 'class': 'строка-название класса'}\n",
    "#     ds_test = TestData(test_folder, path_to_classes_json)\n",
    "#     dl_test = torch.utils.data.DataLoader(\n",
    "#         ds_test,\n",
    "#         batch_size=1,\n",
    "#         shuffle=False,\n",
    "#         num_workers=1\n",
    "#     )\n",
    "#     model.eval()\n",
    "#     results = []\n",
    "#     for image, img_path, class_idx in dl_test:\n",
    "#         img_class = model.predict(image.to(DEVICE)).cpu().detach().numpy()\n",
    "#         results.append({'filename': img_path[0], 'class': ds_test.classes[img_class]})\n",
    "#     return results\n",
    "\n",
    "\n",
    "# def test_classifier(\n",
    "#     model: torch.nn.Module,\n",
    "#     test_folder: str,\n",
    "#     annotations_file: str,\n",
    "# ) -> typing.Tuple[float, float, float]:\n",
    "#     \"\"\"\n",
    "#     Функция для тестирования качества модели.\n",
    "#     Возвращает точность на всех знаках, Recall на редких знаках и Recall на частых знаках.\n",
    "\n",
    "#     :param model: модель, которую нужно протестировать\n",
    "#     :param test_folder: путь до папки с тестовыми данными\n",
    "#     :param annotations_file: путь до .csv-файла с аннотациями (опциональный)\n",
    "#     \"\"\"\n",
    "#     path_to_classes_json = \"./classes.json\"\n",
    "#     def read_csv(filename):\n",
    "#         res = {}\n",
    "#         with open(filename) as fhandle:\n",
    "#             reader = csv.DictReader(fhandle)\n",
    "#             for row in reader:\n",
    "#                 res[row[\"filename\"]] = row[\"class\"]\n",
    "#         return res\n",
    "\n",
    "\n",
    "#     def calc_metric(y_true, y_pred, cur_type, class_name_to_type):\n",
    "#         ok_cnt = 0\n",
    "#         all_cnt = 0\n",
    "#         for t, p in zip(y_true, y_pred):\n",
    "#             if cur_type == \"all\" or class_name_to_type[t] == cur_type:\n",
    "#                 all_cnt += 1\n",
    "#                 if t == p:\n",
    "#                     ok_cnt += 1\n",
    "#         return ok_cnt / max(1, all_cnt)\n",
    "#     output = apply_classifier(model, test_folder, path_to_classes_json)\n",
    "#     output = {elem['filename']: elem['class'] for elem in output}\n",
    "#     gt = read_csv(annotations_file)\n",
    "#     y_pred = []\n",
    "#     y_true = []\n",
    "\n",
    "#     for k, v in output.items():\n",
    "#         y_pred.append(v)\n",
    "#         y_true.append(gt[k])\n",
    "\n",
    "#     with open(path_to_classes_json, \"r\") as fr:\n",
    "#         classes_info = json.load(fr)\n",
    "#     class_name_to_type = {k: v['type'] for k, v in classes_info.items()}\n",
    "\n",
    "#     total_acc = calc_metric(y_true, y_pred, 'all', class_name_to_type)\n",
    "#     rare_recall = calc_metric(y_true, y_pred, 'rare', class_name_to_type)\n",
    "#     freq_recall = calc_metric(y_true, y_pred, 'freq', class_name_to_type)\n",
    "#     return total_acc, rare_recall, freq_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [15:17,  4.47s/it]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import typing\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from numpy.random import randint, choice\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import csv\n",
    "import json\n",
    "import tqdm\n",
    "import pickle\n",
    "import typing\n",
    "import cv2\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from run import calc_metric\n",
    "\n",
    "class SignGenerator(object):\n",
    "    \"\"\"\n",
    "    Класс для генерации синтетических данных.\n",
    "\n",
    "    :param background_path: путь до папки с изображениями фона\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, background_path: str) -> None:\n",
    "        super().__init__()\n",
    "        self.paths = []\n",
    "        for image in os.listdir(background_path):\n",
    "            self.paths.append(os.path.join(background_path, image))\n",
    "\n",
    "    ### Для каждого из необходимых преобразований над иконками/картинками,\n",
    "    ### напишите вспомогательную функцию приблизительно следующего вида:\n",
    "    ###\n",
    "    ### @staticmethod\n",
    "    ### def discombobulate_icon(icon: np.ndarray) -> np.ndarray:\n",
    "    ###     ### YOUR CODE HERE\n",
    "    ###     return ...\n",
    "    ###\n",
    "    ### Постарайтесь не использовать готовые библиотечные функции для\n",
    "    ### аугментаций и преобразования картинок, а реализовать их\n",
    "    ### \"из первых принципов\" на numpy\n",
    "    \n",
    "    @staticmethod\n",
    "    def resize_icon(icon: np.ndarray) -> np.ndarray:\n",
    "        size = np.random.randint(16, 128)\n",
    "        return cv2.resize(icon, (size, size))\n",
    "\n",
    "    @staticmethod\n",
    "    def pad_icon(icon: np.ndarray) -> np.ndarray:\n",
    "        h, w = icon.shape[:2]\n",
    "        pad_percentage = random.randint(0, 15) / 100\n",
    "        pad_w = int(w * pad_percentage)\n",
    "        pad_h = int(h * pad_percentage)\n",
    "        return np.pad(icon, ((pad_h, pad_h), (pad_w, pad_w), (0, 0)))\n",
    "\n",
    "    @staticmethod\n",
    "    def change_color_icon(icon: np.ndarray) -> np.ndarray:\n",
    "        hsv = cv2.cvtColor(icon[:, :, :3], cv2.COLOR_RGB2HSV)\n",
    "        hsv[:, :, 0] = np.random.randint(0, 256)\n",
    "        icon[:, :, :3] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "        return icon\n",
    "\n",
    "    @staticmethod\n",
    "    def rotate_icon(icon: np.ndarray) -> np.ndarray:\n",
    "        angle = random.randint(-15, 15)\n",
    "        r, c = icon.shape[:2]\n",
    "        return cv2.warpAffine(icon, cv2.getRotationMatrix2D((c / 2, r / 2), angle, 1), (c, r))\n",
    "\n",
    "    @staticmethod\n",
    "    def blur_icon(icon: np.ndarray) -> np.ndarray:\n",
    "        kernel = np.zeros((3, 3))\n",
    "        kernel[1, 0] = 1\n",
    "        angle = random.randint(-90, 90)\n",
    "        kernel = cv2.warpAffine(kernel, cv2.getRotationMatrix2D((3 / 2, 3 / 2), angle, 1), (3, 3))\n",
    "        return cv2.filter2D(icon, -1, kernel)\n",
    "\n",
    "    @staticmethod\n",
    "    def gauss_icon(icon: np.ndarray) -> np.ndarray:\n",
    "        return cv2.GaussianBlur(icon, (3,3), 3)\n",
    "\n",
    "    def get_sample(self, icon: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Функция, встраивающая иконку на случайное изображение фона.\n",
    "\n",
    "        :param icon: Массив с изображением иконки\n",
    "        \"\"\"\n",
    "        icon = np.array(Image.open(icon).convert(\"RGBA\"))\n",
    "        icon = self.resize_icon(icon)\n",
    "        icon = self.pad_icon(icon)\n",
    "        icon = self.change_color_icon(icon)\n",
    "        icon = self.rotate_icon(icon)\n",
    "        icon = self.blur_icon(icon)\n",
    "        icon = self.gauss_icon(icon)\n",
    "        \n",
    "        bg = cv2.imread(self.paths[random.randint(0, len(self.paths) - 1)])\n",
    "        \n",
    "        h, w = icon.shape[:2]\n",
    "        x = random.randint(0, bg.shape[1] - w)\n",
    "        y = random.randint(0, bg.shape[0] - h)\n",
    "        bg = bg[y : y + h, x : x + w]\n",
    "        mask = icon[:, :, 3]\n",
    "        icon = icon[:, :, :3]\n",
    "        bg[mask > 0] = icon[mask > 0]\n",
    "        return bg\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "def generate_one_icon(args):\n",
    "    \"\"\"\n",
    "    Функция, генерирующая синтетические данные для одного класса.\n",
    "    :param args: Это список параметров: [путь до файла с иконкой, путь до выходной папки, путь до папки с фонами, число примеров каждого класса]\n",
    "    \"\"\"\n",
    "    icon_path, out_dir, background_path, n, icon = args\n",
    "    generator = SignGenerator(background_path)\n",
    "    out_dir = os.path.join(out_dir, icon[:-4])\n",
    "    for i in range(n):\n",
    "        image = generator.get_sample(icon_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        filename = os.path.join(out_dir, f'{i:06}.png')\n",
    "        cv2.imwrite(os.path.join(out_dir, filename), image)\n",
    "\n",
    "    # path_icon = args[0]\n",
    "    # path_out_dir = args[1]\n",
    "    # path_back_dir = args[2]\n",
    "    # n = args[3]\n",
    "    # # name = args[4][:-4]\n",
    "    # generator = SignGenerator(path_back_dir)\n",
    "    \n",
    "    # for i in range(n):\n",
    "    #     image = generator.get_sample(path_icon)\n",
    "    #     plt.imshow(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    #     plt.axis('off')  # Отключаем оси\n",
    "    #     plt.show()  # Показываем изображение\n",
    "import shutil\n",
    "    # return\n",
    "def generate_all_data(\n",
    "    output_folder: str,\n",
    "    icons_path: str,\n",
    "    background_path: str,\n",
    "    samples_per_class: int = 1000,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Функция, генерирующая синтетические данные.\n",
    "    Эта функция запускает пул параллельно работающих процессов, каждый из которых будет генерировать иконку своего типа.\n",
    "    Это необходимо, так как процесс генерации очень долгий.\n",
    "    Каждый процесс работает в функции generate_one_icon.\n",
    "\n",
    "    :param output_folder: Путь до выходной директории\n",
    "    :param icons_path: Путь до директории с иконками\n",
    "    :param background_path: Путь до директории с картинками фона\n",
    "    :param samples_per_class: Количество примеров каждого класса, которые надо сгенерировать\n",
    "    \"\"\"\n",
    "    for image in os.listdir(icons_path):\n",
    "        os.mkdir(os.path.join(output_folder, image[:-4]))\n",
    "    with ProcessPoolExecutor(8) as executor:\n",
    "        params = [\n",
    "            [\n",
    "                os.path.join(icons_path, icon_file),\n",
    "                output_folder,\n",
    "                background_path,\n",
    "                samples_per_class,\n",
    "                icon_file\n",
    "            ]\n",
    "            for icon_file in os.listdir(icons_path)\n",
    "        ]\n",
    "        list(tqdm.tqdm(executor.map(generate_one_icon, params)))\n",
    "\n",
    "generate_all_data('/home/bakyt/Prog/CV/signs/gen', './icons', './background_images')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bakyt/anaconda3/lib/python3.11/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/home/bakyt/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/bakyt/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/bakyt/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | ResNet           | 25.8 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "17.3 M    Trainable params\n",
      "8.5 M     Non-trainable params\n",
      "25.8 M    Total params\n",
      "103.265   Total estimated model params size (MB)\n",
      "155       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c1f375fb234cf6a19243e723cc562a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bakyt/anaconda3/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomNetwork(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=205, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import typing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import albumentations as A\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import scipy\n",
    "import skimage\n",
    "import skimage.filters\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# !Этих импортов достаточно для решения данного задания\n",
    "import cv2\n",
    "\n",
    "CLASSES_CNT = 205\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class DatasetRTSD(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Класс для чтения и хранения датасета.\n",
    "\n",
    "    :param root_folders: список путей до папок с данными\n",
    "    :param path_to_classes_json: путь до classes.json\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_folders: typing.List[str],\n",
    "        path_to_classes_json: str,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.classes, self.class_to_idx = self.get_classes(path_to_classes_json)\n",
    "        self.samples = []\n",
    "        for root_folder in root_folders:\n",
    "            for folder in os.listdir(root_folder):\n",
    "                path = os.path.join(root_folder, folder)\n",
    "                for filename in os.listdir(path):\n",
    "                    self.samples.append((os.path.join(path, filename), self.class_to_idx[folder]))\n",
    "        self.classes_to_samples = {i: [] for i in range(len(self.classes))}\n",
    "        for i, (img_path, class_idx) in enumerate(self.samples):\n",
    "            self.classes_to_samples[class_idx].append(i)\n",
    "\n",
    "        self.augmentations = A.Compose([\n",
    "            A.Rotate(limit=30),\n",
    "        ])\n",
    "\n",
    "        self.transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(size=(64, 64)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index: int) -> typing.Tuple[torch.Tensor, str, int]:\n",
    "        \"\"\"\n",
    "        Возвращает тройку: тензор с картинкой, путь до файла, номер класса файла (если нет разметки, то \"-1\").\n",
    "        \"\"\"\n",
    "        img_path, class_idx = self.samples[index]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        aug_img_pts = self.augmentations(image=np.array(image, dtype=np.uint8))\n",
    "        aug_image = aug_img_pts[\"image\"]\n",
    "        image = Image.fromarray(aug_image.astype(np.uint8))\n",
    "        image = self.transform(image)\n",
    "        return image, img_path, class_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def get_classes(\n",
    "        path_to_classes_json,\n",
    "    ) -> typing.Tuple[typing.List[str], typing.Mapping[str, int]]:\n",
    "        \"\"\"\n",
    "        Считывает из classes.json информацию о классах.\n",
    "\n",
    "        :param path_to_classes_json: путь до classes.json\n",
    "        \"\"\"\n",
    "        with open(path_to_classes_json, 'r') as f:\n",
    "            class_to_idx = {name: info[\"id\"] for name, info in json.load(f).items()}\n",
    "        return list(class_to_idx.keys()), class_to_idx\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Возвращает размер датасета (количество сэмплов).\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "\n",
    "class TestData(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Класс для чтения и хранения тестового датасета.\n",
    "\n",
    "    :param root: путь до папки с картинками знаков\n",
    "    :param path_to_classes_json: путь до classes.json\n",
    "    :param annotations_file: путь до .csv-файла с аннотациями (опциональный)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        path_to_classes_json: str,\n",
    "        annotations_file: str = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.samples = []\n",
    "        for image in os.listdir(root):\n",
    "            self.samples.append(image)\n",
    "        self.transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(size=(64, 64)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "        self.targets = None\n",
    "        self.classes, self.class_to_idx = self.get_classes(path_to_classes_json)\n",
    "        if annotations_file is not None:\n",
    "            self.targets = {}\n",
    "            with open(annotations_file, 'r') as f:\n",
    "                next(f)\n",
    "                for line in f:\n",
    "                    img_path, class_name = line.strip().split(',')\n",
    "                    self.targets[img_path] = self.class_to_idx[class_name]\n",
    "\n",
    "    def __getitem__(self, index: int) -> typing.Tuple[torch.Tensor, str, int]:\n",
    "        \"\"\"\n",
    "        Возвращает тройку: тензор с картинкой, путь до файла, номер класса файла (если нет разметки, то \"-1\").\n",
    "        \"\"\"\n",
    "        img_path = self.samples[index]\n",
    "        image = Image.open(os.path.join(self.root, img_path)).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        class_idx = self.targets.get(img_path, -1) if self.targets else -1\n",
    "        return image, img_path, class_idx\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_classes(\n",
    "        path_to_classes_json,\n",
    "    ) -> typing.Tuple[typing.List[str], typing.Mapping[str, int]]:\n",
    "        \"\"\"\n",
    "        Считывает из classes.json информацию о классах.\n",
    "\n",
    "        :param path_to_classes_json: путь до classes.json\n",
    "        \"\"\"\n",
    "        with open(path_to_classes_json, 'r') as f:\n",
    "            class_to_idx = {name: info[\"id\"] for name, info in json.load(f).items()}\n",
    "        return list(class_to_idx.keys()), class_to_idx\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Возвращает размер датасета (количество сэмплов).\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "class CustomNetwork(L.LightningModule):\n",
    "    \"\"\"\n",
    "    Класс, реализующий нейросеть для классификации.\n",
    "\n",
    "    :param features_criterion: loss-функция на признаки, извлекаемые нейросетью перед классификацией (None когда нет такого лосса)\n",
    "    :param internal_features: внутреннее число признаков\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        features_criterion: (\n",
    "            typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor] | None\n",
    "        ) = None,\n",
    "        internal_features: int = 1024,\n",
    "        transfer = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        model = torchvision.models.resnet50(pretrained=transfer)\n",
    "        old_in_features = model.fc.in_features\n",
    "        model.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(old_in_features, internal_features),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(internal_features, CLASSES_CNT)\n",
    "        )\n",
    "        for child in list(model.children())[:-3]:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.model = model.to(DEVICE)\n",
    "        self.features_criterion = features_criterion\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Функция для прогона данных через нейронную сеть.\n",
    "        Возвращает два тензора: внутреннее представление и логиты после слоя-классификатора.\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "    def predict(self, x: torch.Tensor) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Функция для предсказания классов-ответов. Возвращает np-массив с индексами классов.\n",
    "\n",
    "        :param x: батч с картинками\n",
    "        \"\"\"\n",
    "        return self.forward(x).argmax(dim=1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=5e-4)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=5,\n",
    "            gamma=0.1,\n",
    "        )\n",
    "        lr_scheduler_config = {\n",
    "            \"scheduler\": lr_scheduler,\n",
    "            \"interval\": \"epoch\",\n",
    "            \"frequency\": 1,\n",
    "        }\n",
    "        return [optimizer], [lr_scheduler_config]\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        x, _, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        accs = (logits.argmax(dim=1) == y).sum() / y.shape[0]\n",
    "        metrics = {}\n",
    "        if loss is not None:\n",
    "            metrics[f\"train_loss\"] = loss\n",
    "        if accs is not None:\n",
    "            metrics[f\"train_accs\"] = accs\n",
    "        self.log_dict(\n",
    "            metrics,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "            on_step=\"train\" == \"train\",\n",
    "            on_epoch=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_simple_classifier() -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Функция для обучения простого классификатора на исходных данных.\n",
    "    \"\"\"\n",
    "    ds_train = DatasetRTSD(\n",
    "        root_folders=['./cropped-train'],\n",
    "        path_to_classes_json='./classes.json'\n",
    "    )\n",
    "    dl_train = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=os.cpu_count(),\n",
    "    )\n",
    "    model = CustomNetwork(transfer=True)\n",
    "    trainer = L.Trainer(max_epochs=1)\n",
    "    trainer.fit(model, dl_train)\n",
    "    torch.save(model.state_dict(), \"simple_model.pth\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def apply_classifier(\n",
    "    model: torch.nn.Module,\n",
    "    test_folder: str,\n",
    "    path_to_classes_json: str,\n",
    ") -> typing.List[typing.Mapping[str, typing.Any]]:\n",
    "    \"\"\"\n",
    "    Функция, которая применяет модель и получает её предсказания.\n",
    "\n",
    "    :param model: модель, которую нужно протестировать\n",
    "    :param test_folder: путь до папки с тестовыми данными\n",
    "    :param path_to_classes_json: путь до файла с информацией о классах classes.json\n",
    "    \"\"\"\n",
    "    ds_test = TestData(test_folder, path_to_classes_json)\n",
    "    dl_test = torch.utils.data.DataLoader(\n",
    "        ds_test,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=1\n",
    "    )\n",
    "    model.eval()\n",
    "    results = []\n",
    "    for image, img_path, class_idx in dl_test:\n",
    "        img_class = model.predict(image.to('cpu')).cpu().detach().numpy().ravel().item()\n",
    "        results.append({'filename': img_path[0], 'class': ds_test.classes[img_class]})\n",
    "    return results\n",
    "\n",
    "\n",
    "def test_classifier(\n",
    "    model: torch.nn.Module,\n",
    "    test_folder: str,\n",
    "    annotations_file: str,\n",
    ") -> typing.Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Функция для тестирования качества модели.\n",
    "    Возвращает точность на всех знаках, Recall на редких знаках и Recall на частых знаках.\n",
    "\n",
    "    :param model: модель, которую нужно протестировать\n",
    "    :param test_folder: путь до папки с тестовыми данными\n",
    "    :param annotations_file: путь до .csv-файла с аннотациями (опциональный)\n",
    "    \"\"\"\n",
    "    path_to_classes_json='./classes.json'\n",
    "    def read_csv(filename):\n",
    "        res = {}\n",
    "        with open(filename) as fhandle:\n",
    "            reader = csv.DictReader(fhandle)\n",
    "            for row in reader:\n",
    "                res[row[\"filename\"]] = row[\"class\"]\n",
    "        return res\n",
    "\n",
    "    def calc_metric(y_true, y_pred, cur_type, class_name_to_type):\n",
    "        ok_cnt = 0\n",
    "        all_cnt = 0\n",
    "        for t, p in zip(y_true, y_pred):\n",
    "            if cur_type == \"all\" or class_name_to_type[t] == cur_type:\n",
    "                all_cnt += 1\n",
    "                if t == p:\n",
    "                    ok_cnt += 1\n",
    "        return ok_cnt / max(1, all_cnt)\n",
    "\n",
    "    results = apply_classifier(model, test_folder, path_to_classes_json)\n",
    "    gt = read_csv(annotations_file)\n",
    "    y_pred = [elem['class'] for elem in results]\n",
    "    y_true = [gt[elem['filename']] for elem in results]\n",
    "    \n",
    "    with open(path_to_classes_json, 'r') as f:\n",
    "        class_to_type = {name: info[\"type\"] for name, info in json.load(f).items()}\n",
    "    \n",
    "    total_acc = calc_metric(y_true, y_pred, 'all', class_to_type)\n",
    "    rare_recall = calc_metric(y_true, y_pred, 'rare', class_to_type)\n",
    "    freq_recall = calc_metric(y_true, y_pred, 'freq', class_to_type)\n",
    "    return total_acc, rare_recall, freq_recall\n",
    "\n",
    "\n",
    "class SignGenerator(object):\n",
    "    \"\"\"\n",
    "    Класс для генерации синтетических данных.\n",
    "\n",
    "    :param background_path: путь до папки с изображениями фона\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, background_path: str) -> None:\n",
    "        super().__init__()\n",
    "        self.paths = []\n",
    "        for image in os.listdir(background_path):\n",
    "            self.paths.append(os.path.join(background_path, image))\n",
    "\n",
    "    ### Для каждого из необходимых преобразований над иконками/картинками,\n",
    "    ### напишите вспомогательную функцию приблизительно следующего вида:\n",
    "    ###\n",
    "    ### @staticmethod\n",
    "    ### def discombobulate_icon(icon: np.ndarray) -> np.ndarray:\n",
    "    ###     ### YOUR CODE HERE\n",
    "    ###     return ...\n",
    "    ###\n",
    "    ### Постарайтесь не использовать готовые библиотечные функции для\n",
    "    ### аугментаций и преобразования картинок, а реализовать их\n",
    "    ### \"из первых принципов\" на numpy\n",
    "    \n",
    "    @staticmethod\n",
    "    def resize_icon(icon: np.ndarray) -> np.ndarray:\n",
    "        size = np.random.randint(16, 128)\n",
    "        return cv2.resize(icon, (size, size))\n",
    "\n",
    "    @staticmethod\n",
    "    def pad_icon(icon: np.ndarray) -> np.ndarray:\n",
    "        h, w = icon.shape[:2]\n",
    "        pad_percentage = random.randint(0, 15) / 100\n",
    "        pad_w = int(w * pad_percentage)\n",
    "        pad_h = int(h * pad_percentage)\n",
    "        return np.pad(icon, ((pad_h, pad_h), (pad_w, pad_w), (0, 0)))\n",
    "\n",
    "    @staticmethod\n",
    "    def change_color_icon(icon: np.ndarray) -> np.ndarray:\n",
    "        hsv = cv2.cvtColor(icon[:, :, :3], cv2.COLOR_RGB2HSV)\n",
    "        hsv[:, :, 0] = np.random.randint(0, 256)\n",
    "        icon[:, :, :3] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "        return icon\n",
    "\n",
    "    @staticmethod\n",
    "    def rotate_icon(icon: np.ndarray) -> np.ndarray:\n",
    "        angle = random.randint(-15, 15)\n",
    "        r, c = icon.shape[:2]\n",
    "        return cv2.warpAffine(icon, cv2.getRotationMatrix2D((c / 2, r / 2), angle, 1), (c, r))\n",
    "\n",
    "    @staticmethod\n",
    "    def blur_icon(icon: np.ndarray) -> np.ndarray:\n",
    "        kernel = np.zeros((3, 3))\n",
    "        kernel[1, 0] = 1\n",
    "        angle = random.randint(-90, 90)\n",
    "        kernel = cv2.warpAffine(kernel, cv2.getRotationMatrix2D((3 / 2, 3 / 2), angle, 1), (3, 3))\n",
    "        return cv2.filter2D(icon, -1, kernel)\n",
    "\n",
    "    @staticmethod\n",
    "    def gauss_icon(icon: np.ndarray) -> np.ndarray:\n",
    "        return cv2.GaussianBlur(icon, (3,3), 3)\n",
    "\n",
    "    def get_sample(self, icon: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Функция, встраивающая иконку на случайное изображение фона.\n",
    "\n",
    "        :param icon: Массив с изображением иконки\n",
    "        \"\"\"\n",
    "        icon = np.array(Image.open(icon).convert(\"RGBA\"))\n",
    "        icon = self.resize_icon(icon)\n",
    "        icon = self.pad_icon(icon)\n",
    "        icon = self.change_color_icon(icon)\n",
    "        icon = self.rotate_icon(icon)\n",
    "        icon = self.blur_icon(icon)\n",
    "        icon = self.gauss_icon(icon)\n",
    "        \n",
    "        bg = cv2.imread(self.paths[random.randint(0, len(self.paths) - 1)])\n",
    "        \n",
    "        h, w = icon.shape[:2]\n",
    "        x = random.randint(0, bg.shape[1] - w)\n",
    "        y = random.randint(0, bg.shape[0] - h)\n",
    "        bg = bg[y : y + h, x : x + w]\n",
    "        mask = icon[:, :, 3]\n",
    "        icon = icon[:, :, :3]\n",
    "        bg[mask > 0] = icon[mask > 0]\n",
    "        return bg\n",
    "\n",
    "\n",
    "def generate_one_icon(args: typing.Tuple[str, str, str, int]) -> None:\n",
    "    \"\"\"\n",
    "    Функция, генерирующая синтетические данные для одного класса.\n",
    "\n",
    "    :param args: Это список параметров: [путь до файла с иконкой, путь до выходной папки, путь до папки с фонами, число примеров каждого класса]\n",
    "    \"\"\"\n",
    "    icon_path, out_dir, background_path, n, icon = args\n",
    "    generator = SignGenerator(background_path)\n",
    "    out_dir = os.path.join(out_dir, icon[:-4])\n",
    "    for i in range(n):\n",
    "        image = generator.get_sample(icon_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        filename = os.path.join(out_dir, f'{i:06}.png')\n",
    "        cv2.imwrite(os.path.join(out_dir, filename), image)\n",
    "\n",
    "\n",
    "def generate_all_data(\n",
    "    output_folder: str,\n",
    "    icons_path: str,\n",
    "    background_path: str,\n",
    "    samples_per_class: int = 1000,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Функция, генерирующая синтетические данные.\n",
    "    Эта функция запускает пул параллельно работающих процессов, каждый из которых будет генерировать иконку своего типа.\n",
    "    Это необходимо, так как процесс генерации очень долгий.\n",
    "    Каждый процесс работает в функции generate_one_icon.\n",
    "\n",
    "    :param output_folder: Путь до выходной директории\n",
    "    :param icons_path: Путь до директории с иконками\n",
    "    :param background_path: Путь до директории с картинками фона\n",
    "    :param samples_per_class: Количество примеров каждого класса, которые надо сгенерировать\n",
    "    \"\"\"\n",
    "    for image in os.listdir(icons_path):\n",
    "        os.mkdir(os.path.join(output_folder, image[:-4]))\n",
    "    with ProcessPoolExecutor(8) as executor:\n",
    "        params = [\n",
    "            [\n",
    "                os.path.join(icons_path, icon_file),\n",
    "                output_folder,\n",
    "                background_path,\n",
    "                samples_per_class,\n",
    "                icon_file\n",
    "            ]\n",
    "            for icon_file in os.listdir(icons_path)\n",
    "        ]\n",
    "        list(tqdm.tqdm(executor.map(generate_one_icon, params)))\n",
    "\n",
    "\n",
    "def train_synt_classifier() -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Функция для обучения простого классификатора на смеси исходных и ситетических данных.\n",
    "    \"\"\"\n",
    "    ds_train = DatasetRTSD(\n",
    "        root_folders=['./cropped-train', './gen'],\n",
    "        path_to_classes_json='./classes.json'\n",
    "    )\n",
    "    dl_train = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=os.cpu_count(),\n",
    "        \n",
    "    )\n",
    "    model = CustomNetwork(transfer=True)\n",
    "    trainer = L.Trainer(max_epochs=1)\n",
    "    trainer.fit(model, dl_train)\n",
    "    torch.save(model.state_dict(), \"simple_model_with_synt.pth\")\n",
    "    return model\n",
    "train_synt_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
